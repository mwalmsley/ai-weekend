{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diversif.Hire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a prototype of our Job Description assistant. It...\n",
    "* Takes in an audio file.\n",
    "* Transcribes the audio file using Google Cloud's speech-to-text API.\n",
    "* Identifies the key words and phrases relevant to the job description.\n",
    "* Matches those to skills and experience of candidates.\n",
    "* Writes a job description using gender and racially neutral language.\n",
    "* TADAAAA!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo\n",
    "\n",
    "**Check out our demo video in the slide deck!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Requirements\n",
    "\n",
    "Please see the `README` for installation instructions. I\n",
    "\n",
    "To run the demo, you need some to install some awkward audio libraries to for streaming audio to the program. This notebook has been designed to avoid this by using a local file. You will still need the other requirements, however!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import enums\n",
    "from google.cloud.speech import types\n",
    "from aspect_lookup import Skill, Experience, Quality, Education\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'zoobot-224010.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This transcribes the audio file (the demo uses streaming audio from your microphone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_file(speech_file):\n",
    "    \"\"\"Transcribe the given audio file.\"\"\"\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    with io.open(speech_file, 'rb') as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    audio = types.RecognitionAudio(content=content)\n",
    "    config = types.RecognitionConfig(\n",
    "        encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=16000,\n",
    "        language_code='en-US')\n",
    "\n",
    "    response = client.recognize(config, audio)\n",
    "    # Each result is for a consecutive portion of the audio. Iterate through\n",
    "    # them to get the transcripts for the entire audio file.\n",
    "    # for result in response.results:\n",
    "        # The first alternative is the most likely one for this portion.\n",
    "    return [result.alternatives[0].transcript for result in response.results]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/data_scientist.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-83f8d5a3324d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0maudio_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/data_scientist.wav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtext_transcriptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscribe_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_transcriptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-24b415ab5288>\u001b[0m in \u001b[0;36mtranscribe_file\u001b[0;34m(speech_file)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspeech\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSpeechClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeech_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/data_scientist.wav'"
     ]
    }
   ],
   "source": [
    "audio_loc = 'data/data_scientist.wav'\n",
    "text_transcriptions = transcribe_file(audio_loc)\n",
    "text = ''.join(text_transcriptions)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming you haven't installed SDK, here is some text you can use instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'someone with any degree and industry experience, who creates client value'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The get_aspects function pulls out the keywords from the transcribed text and matches to our keyword bank. The keyword bank is customizable by the company but we also hope to use more advanced NLP to identify sentiment qualifiers and semantic meaning from the transcription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aspects(text):\n",
    "    aspects = []\n",
    "    for aspect in all_aspects:\n",
    "        for keyword in aspect.keywords:\n",
    "            if keyword in text:\n",
    "                aspects.append(aspect)\n",
    "    return aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)\n",
    "print('\\nAspects:')\n",
    "aspects = get_aspects(text)\n",
    "print(aspects)\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aspects_to_advert function looks up the qualities identified in the transcript and elegantly expresses them, populating the job advert for you.\n",
    "\n",
    "The choice of words used have been carefully chosen to avoid gender or racial bias. This helps customers attract a more diverse pool of applicants, leading to better hires. Going forwards, we are looking to use word embeddings and other techniques to best capture the meaning of the user in neutral language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aspects_to_advert(aspects):\n",
    "    skills = [x for x in aspects if isinstance(x, Skill)]\n",
    "    experiences = [x for x in aspects if isinstance(x, Experience)]\n",
    "    educations = [x for x in aspects if isinstance(x, Education)]  # sad s\n",
    "    qualities = [x for x in aspects if isinstance(x, Quality)]  # sad s\n",
    "\n",
    "    if len(skills) > 0:\n",
    "        print('Skills: \\n')\n",
    "        for aspect in skills:\n",
    "            print('- {}'.format(aspect.representation))\n",
    "\n",
    "    if len(experiences) > 0:\n",
    "        print('\\nExperience:')\n",
    "        for aspect in experiences:\n",
    "            print('- {}'.format(aspect.representation))\n",
    "\n",
    "    if len(educations) > 0:\n",
    "        print('\\nEducation:')\n",
    "        for aspect in educations:\n",
    "            print('- {}'.format(aspect.representation))\n",
    "\n",
    "\n",
    "    if len(qualities) > 0:\n",
    "        print('\\nQuality:')\n",
    "        for aspect in qualities:\n",
    "            print('- {}'.format(aspect.representation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspects_to_advert(aspects)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
